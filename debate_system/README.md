# ğŸ§  Autonomous Multi-LLM Markdown Debate Engine

This project simulates a full-scale multi-agent debate using local LLMs via **Ollama**, with agents reasoning entirely in **Markdown** and a fully traceable architecture. Supports MCTS turn logic, Delphi consensus, belief memory, contradiction detection, argument trees, and more.

---

## ğŸš€ Features

- Persona agents with evolving beliefs and roles
- Fully autonomous loop: turn selection â†’ LLM reasoning â†’ belief update
- Supports `round_robin`, `mcts`, `priority`, `interrupt`, `delphi` turn strategies
- Summarizer, contradiction detector, scoring, consensus engine
- Recovery, replay, and persistent session storage
- Argument tree generation and export (Markdown + JSON)
- Real-time Streamlit UI
- Designed for local models (uses `gemma3:latest` via Ollama)

---

## ğŸ§± Folder Structure

```
debate_system/
â”œâ”€â”€ app/                 # Core logic
â”‚   â”œâ”€â”€ persona_agent.py
â”‚   â”œâ”€â”€ mediator_agent.py
â”‚   â”œâ”€â”€ consensus_engine.py
â”‚   â”œâ”€â”€ context_builder.py
â”‚   â”œâ”€â”€ argument_graph.py
â”‚   â”œâ”€â”€ performance_logger.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ tools.py
â”‚   â”œâ”€â”€ flow_control.py
â”‚   â”œâ”€â”€ debate_manager.py
â”‚   â”œâ”€â”€ session_recovery.py
â”‚   â”œâ”€â”€ logger.py
â”‚   â”œâ”€â”€ user_feedback.py
â”‚   â””â”€â”€ integration_plugin.py
â”œâ”€â”€ ui/                  # Streamlit frontend
â”‚   â”œâ”€â”€ streamlit_app.py
â”‚   â””â”€â”€ components.py
â”œâ”€â”€ plugins/             # Custom validators/tools (optional)
â”œâ”€â”€ sessions/            # Output folder per run
â”œâ”€â”€ tests/               # Pytest-based validation
â””â”€â”€ requirements.txt
```

---

## âš™ï¸ Setup

Install Ollama (https://ollama.com) and pull a model:

```bash
ollama pull gemma:7b
```

Create and activate your Python environment:

```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

---

## âœ… Usage

### 1. Launch the UI

Run the following command from the `debate_system` directory:

```bash
python -m streamlit run ui/streamlit_app.py
```

Upload a `.yaml` config file and press â€œStart Debateâ€.

### 2. CLI / Dev Usage

```bash
python3 app/main.py
```

### 3. Explore Output

Results will be saved in:

```
sessions/{session_id}/
â”œâ”€â”€ summary.md            # Markdown debate log
â”œâ”€â”€ summary.json          # Structured output
â”œâ”€â”€ performance_log.json
â”œâ”€â”€ agent_states.json
â”œâ”€â”€ argument_graph.json
â”œâ”€â”€ user_feedback.json
```

---

## ğŸ§  Agent Capabilities

Agents:
- Anchor responses using memory
- Respond using Markdown only
- Avoid self-contradiction
- Adjust beliefs over time
- Interact with mediator and tools

---

## ğŸ§ª Testing

```bash
pytest tests/
```

---

## ğŸ§  Default LLM Setup

All agents run `gemma3:latest` via Ollama, with real streamed chat (`stream=True`).

---

## âœ¨ Contributions

PRs and feature suggestions welcome. Future roadmap includes:
- Live graph visualizer
- Tool sandbox
- Agent retraining via feedback

---

## ğŸ§  Maintained by

Gil B. + ChatGPT
